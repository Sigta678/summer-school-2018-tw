{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//## 0. Prepare Images: Review of OpenCV or What OpenCV group can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mix with OpenCV for demo\n",
    "# import the images that we need in the task: load it on GitHub first\n",
    "\n",
    "#(x_img_train,y_label_train),(x_img_test,y_label_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "label_dict={0:\"airplane\",1:\"automobile\",2:\"bird\",3:\"cat\",4:\"deer\",\n",
    "            5:\"dog\",6:\"frog\",7:\"horse\",8:\"ship\",9:\"truck\"}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "32\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f0e8a3593d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e955eab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see what our data looks like\n",
    "'''\n",
    "i = 1\n",
    "pic = plt.subplot()\n",
    "print(x_img_train[i].shape)\n",
    "print(x_img_train[i].shape[0])\n",
    "print(x_img_train[i].shape[2])\n",
    "pic.imshow(x_img_train[i])\n",
    "title = label_dict[y_label_train[i][0]]\n",
    "pic.set_title(title,fontsize=20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([154, 177, 187], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for RGB\n",
    "x_img_train[i][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize, choose 3 picture: 0:2\n",
    "#x_train_normalize = x_img_train[0:2][0][0].astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_normalize[i][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_label_onehot = np_utils.to_categorical(y_label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create placeholder: The pre-allocate dimensions for input & output\n",
    "![Placeholder](https://imgur.com/lTf4ehx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32,[None,n_H0,n_W0,n_C0])\n",
    "    Y = tf.placeholder(tf.float32,[None,n_y])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(64, 64, 3, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Example: Placeholder + one-hot (feat. Deep Q Network, the block you will see at last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Network input\n",
    "# state = 4?\n",
    "networkstate = tf.placeholder(tf.float32, [None, 4], name=\"input\")\n",
    "networkaction = tf.placeholder(tf.int32, [None], name=\"actioninput\")\n",
    "networkreward = tf.placeholder(tf.float32,[None], name=\"groundtruth_reward\")\n",
    "# action = 2 (right,left)?\n",
    "# Network output\n",
    "action_onehot = tf.one_hot(networkaction, 2, name=\"actiononehot\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define the weight of CNN: filter size & channel (With initialized parameters)\n",
    "- ## Filter example\n",
    "![Sobel filter](https://imgur.com/YaAq4q7.png)\n",
    "- ## After filter\n",
    "![Human](https://imgur.com/C8XqlHm.png)\n",
    "- ## Channel\n",
    "![RGB](https://imgur.com/ygKlPRO.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    # so that your \"random\" numbers match ours\n",
    "    tf.set_random_seed(1)                              \n",
    "    \n",
    "    # store weight\n",
    "    # filter_width:4,filter_height:4,input_channel:3,output_channel:8\n",
    "    W1 = tf.get_variable(\"W1\", [4,4,3,8], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    # filter_width:2,filter_height:2,input_channel:8,output_channel:16\n",
    "    W2 = tf.get_variable(\"W2\", [2,2,8,16], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "    # make it into a dictionary of parameters\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1_first graph_channel values = [ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394\n",
      " -0.06847463  0.05245192]\n",
      "W2_first graph_channel values = [-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
      " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
      " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n"
     ]
    }
   ],
   "source": [
    "# have a look inside the weight\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    print(\"W1_first graph_channel values = \" + str(parameters[\"W1\"].eval()[1,1,1]))\n",
    "    print(\"W2_first graph_channel values = \" + str(parameters[\"W2\"].eval()[1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output:**\n",
    "\n",
    "<table> \n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "        W1_first graph_channel values = \n",
    "        </td>\n",
    "        <td>\n",
    "[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394 <br>\n",
    " -0.06847463  0.05245192]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "        W2_first graph_channel values = \n",
    "        </td>\n",
    "        <td>\n",
    "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058 <br>\n",
    " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228 <br>\n",
    " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Example (feat. Deep Q Network, the block you will see at last) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# The variable in our network: \n",
    "w1 = tf.Variable(tf.random_normal([4,16], stddev=0.35), name=\"W1\")\n",
    "w2 = tf.Variable(tf.random_normal([16,32], stddev=0.35), name=\"W2\")\n",
    "w3 = tf.Variable(tf.random_normal([32,8], stddev=0.35), name=\"W3\")\n",
    "w4 = tf.Variable(tf.random_normal([8,2], stddev=0.35), name=\"W4\")\n",
    "b1 = tf.Variable(tf.zeros([16]), name=\"B1\")\n",
    "b2 = tf.Variable(tf.zeros([32]), name=\"B2\")\n",
    "b3 = tf.Variable(tf.zeros([8]), name=\"B3\")\n",
    "b4 = tf.Variable(tf.zeros(2), name=\"B4\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3-1 Understanding the blocks/layers -- Learning of strides, channel, Flatten(), & Fully_Connected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some definitions of functions \n",
    "(you can check on Tensorflow for other function used: https://www.tensorflow.org/api_docs/python/tf)\n",
    "## Hint for 1.3-1 (<span style=\"color:red\">Reproducing graphic concepts: CNN & Max Pool</span>)\n",
    "- ### tf.nn.conv2d()\n",
    "- ### tf.nn.max_pool()\n",
    "- ### tf.contrib.layers.flatten()\n",
    "- ### tf.contrib.layers.fully_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):       \n",
    "    \n",
    "    s = \"---------------------------------------------------------------\"\n",
    "    print(s)\n",
    "    print(\"Layer    Height    Width    Channel    Node   | What you will see\")\n",
    "    print(s)\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    \n",
    "    print(\"Input    %d        %d        %d                | %s\" % (X.shape[1],X.shape[2],X.shape[3],X.shape))\n",
    "    \n",
    "    #[batch, in_height, in_width, in_channels],[filter_height, filter_width, in_channels, out_channels],[1, stride, stride, 1]\n",
    "    # Conv\n",
    "    s1_h = 2\n",
    "    s1_w = 2\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,s1_h,s1_w,1], padding = 'SAME')\n",
    "    print(\"Conv     \"+str(Z1.shape[1])+\"        \"+str(Z1.shape[2])+\"        \"+str(Z1.shape[3])+\"                | \"+str(Z1.shape))\n",
    "    # ReLU\n",
    "    #A1 = tf.nn.relu(Z1)\n",
    "    # Max Pool\n",
    "    sp1_h = 4\n",
    "    sp1_w = 4\n",
    "    P1 = tf.nn.max_pool(Z1, ksize = [1,sp1_h,sp1_w,1], strides = [1,sp1_h,sp1_w,1], padding = 'SAME')\n",
    "    print(\"Max Pool  %d         %d        %d                | %s\" %(P1.shape[1],P1.shape[2],P1.shape[3],P1.shape))\n",
    "    # Flatten\n",
    "    F1 = tf.contrib.layers.flatten(P1)\n",
    "    #print(\"Flatten\",F1.shape[1],F1.shape)\n",
    "    print(\"Flatten                                %d    | %s\" %(F1.shape[1],F1.shape))\n",
    "    # Fully Connected\n",
    "    Y1 = tf.contrib.layers.fully_connected(F1, num_outputs=6,activation_fn=None)\n",
    "    print(\"Fully Connected                          %d    | %s\" %(Y1.shape[1],Y1.shape))\n",
    "    \n",
    "    print(s)\n",
    "    print(\"Conv_process(Between Layer: Input & Conv)\")\n",
    "    print(\"|__ Filter shape: \"+str(W1.shape))\n",
    "    print(\"|__ Stride_height: %d, Stride_width: %d\" %(s1_h,s1_w))\n",
    "    print(\"|__ How it works: See CNN operation below\")\n",
    "    \n",
    "    print(\"\\nPool_process(Between Layer: Conv & Max Pool)\")\n",
    "    print(\"|__ Filter_height: %d, Filter_width: %d\" %(sp1_h,sp1_w))\n",
    "    print(\"|__ Stride_height: %d, Stride_width: %d\" %(sp1_h,sp1_w))\n",
    "    print(\"|__ How it works: See Max Pooling operation below\")\n",
    "    \n",
    "    print(\"\\nFlatten_process(Between Layer: Max Pool & Flatten)\")\n",
    "    print(\"|__ Flatten_input: (%d,%d,%d)\" %(P1.shape[1],P1.shape[2],P1.shape[3]))\n",
    "    print(\"|__ Flatten_output: %d*%d*%d = %d\" %(P1.shape[1],P1.shape[2],P1.shape[3],P1.shape[1]*P1.shape[2]*P1.shape[3]))\n",
    "    return Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "Layer    Height    Width    Channel    Node   | What you will see\n",
      "---------------------------------------------------------------\n",
      "Input    32        32        3                | (?, 32, 32, 3)\n",
      "Conv     16        16        8                | (?, 16, 16, 8)\n",
      "Max Pool  4         4        8                | (?, 4, 4, 8)\n",
      "Flatten                                128    | (?, 128)\n",
      "Fully Connected                          6    | (?, 6)\n",
      "---------------------------------------------------------------\n",
      "Conv_process(Between Layer: Input & Conv)\n",
      "|__ Filter shape: (4, 4, 3, 8)\n",
      "|__ Stride_height: 2, Stride_width: 2\n",
      "\n",
      "Pool_process(Between Layer: Conv & Max Pool)\n",
      "|__ Filter_height: 4, Filter_width: 4\n",
      "|__ Stride_height: 4, Stride_width: 4\n",
      "\n",
      "Flatten_process(Between Layer: Max Pool & Flatten)\n",
      "|__ Flatten_input: (4,4,8)\n",
      "|__ Flatten_output: 4*4*8 = 128\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # create_placeholders(H,W,C,Output): the function you defined\n",
    "    X,Y = create_placeholders(32,32,3,10)\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    Z = forward_propagation(X,parameters)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN operation\n",
    "![CNN](https://imgur.com/FIy5Ou4.gif)\n",
    "### Max Pooling operation (Vote for the largest number)\n",
    "![Max Pool](https://imgur.com/ec0zNkC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary(pretrained_YOLO)\n",
    "#from keras.models import load_model\n",
    "# H5 file is created by yad2k.py\n",
    "# some problems in .cfg .weight -> .h5\n",
    "# yolo_model = load_model(\"yolov3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3-1 Example*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex.1 Placeholder + one-hot + define variable + NN + Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network placeholder: input\n",
    "networkstate = tf.placeholder(tf.float32, [None, 4], name=\"input\")\n",
    "networkaction = tf.placeholder(tf.int32, [None], name=\"actioninput\")\n",
    "networkreward = tf.placeholder(tf.float32,[None], name=\"groundtruth_reward\")\n",
    "# network placeholder: output, final result with probability\n",
    "action_onehot = tf.one_hot(networkaction, 2, name=\"actiononehot\")\n",
    "\n",
    "# The variable in our network: \n",
    "w1 = tf.Variable(tf.random_normal([4,16], stddev=0.35), name=\"W1\")\n",
    "w2 = tf.Variable(tf.random_normal([16,32], stddev=0.35), name=\"W2\")\n",
    "w3 = tf.Variable(tf.random_normal([32,8], stddev=0.35), name=\"W3\")\n",
    "w4 = tf.Variable(tf.random_normal([8,2], stddev=0.35), name=\"W4\")\n",
    "b1 = tf.Variable(tf.zeros([16]), name=\"B1\")\n",
    "b2 = tf.Variable(tf.zeros([32]), name=\"B2\")\n",
    "b3 = tf.Variable(tf.zeros([8]), name=\"B3\")\n",
    "b4 = tf.Variable(tf.zeros(2), name=\"B4\")\n",
    "\n",
    "# The network layout\n",
    "layer1 = tf.nn.relu(tf.add(tf.matmul(networkstate,w1), b1), name=\"Result1\")\n",
    "layer2 = tf.nn.relu(tf.add(tf.matmul(layer1,w2), b2), name=\"Result2\")\n",
    "layer3 = tf.nn.relu(tf.add(tf.matmul(layer2,w3), b3), name=\"Result3\")\n",
    "predictedreward = tf.add(tf.matmul(layer3,w4), b4, name=\"predictedReward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex.2 CNN + Max Pooling + Flatten + Fully Connected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def your_forward_prop(X,parameters):\n",
    "    # your input data size\n",
    "    print(\"Input: %s\" % X.shape)\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    # your first conv layer\n",
    "    # your conv filter\n",
    "    w1_h = \n",
    "    w1_w = \n",
    "    in_channel = \n",
    "    out_channel = \n",
    "    W1 = tf.get_variable(\"W1\", [w1_h,w1_w,in_channel,out_channel], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    # your conv stride\n",
    "    s1_h = \n",
    "    s1_w = \n",
    "    Z1 = tf.nn.con2d(X,W1, strides=[1,s1_h,s1_w,1], padding='SAME')\n",
    "    # what you define\n",
    "    print(\"Conv: %s\" % Z1.shape)\n",
    "    print(\"|__ Filter_height: %d, Filter_weight: %d\" %(w1_h,w1_w))\n",
    "    \n",
    "    # your first max_pooling layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output: Not Yet**\n",
    "\n",
    "<table> \n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "        W1_first graph_channel values = \n",
    "        </td>\n",
    "        <td>\n",
    "[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394 <br>\n",
    " -0.06847463  0.05245192]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "        W2_first graph_channel values = \n",
    "        </td>\n",
    "        <td>\n",
    "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058 <br>\n",
    " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228 <br>\n",
    " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3-3 (Advance) More techniques on model structure -- ResNet (Reduce the back-prop), Concatence, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3-4 (In other tensorflow materials) Save it into log file, present on tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//## 1.4 How similar the prediction is -- Compute cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//## 1.5 Define the training model: Minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 More on mathematic of gradient descent (Try to do it simple, learning_rate*slope) -- Cost, Optimization, Learning rate\n",
    "- ## 1) Cost function: (formula...)\n",
    "![Optimization](https://imgur.com/LXBjfLb.png)\n",
    "- ## 2) Learning rate\n",
    "![Learning rate](https://imgur.com/J8U8fu9.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6-1 Cost function的意義:  Model \"預測\"結果 和 資料\"實際\"值 的誤差曲線(補cost圖?)\n",
    "- ### Concept: cost越小 -> 預測和實際差異越小 -> 越接近真實特徵\n",
    "- #### Problem: 資料實際樣本太狹隘時，又學到很精 -> 只學到這個群體的特質，不夠 general : 這個結果稱之為 overfit\n",
    "1) 二次函數\n",
    "2) saddle point\n",
    "3) 六次函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = np.array([[1.],[-10.],[25.]])\n",
    "w = tf.Variable(0,dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32,[3,1])\n",
    "\n",
    "# cost = tf.add(tf.add(w**2,tf.multiply(-10.,w),25))\n",
    "# operator overloading\n",
    "# placeholder x, input\n",
    "cost = x[0]*w**2 + x[1]*w + x[2]\n",
    "#[1,2]\n",
    "#[2,4,1]\n",
    "#cost = x[0]*w**4 + x[1]*w**3 + x[2]*w**2\n",
    "#[5,8,3,1]\n",
    "#cost = x[0]*w**6+ x[1]*w**5+ x[2]*w**2+ x[3]*w\n",
    "# broadcasting\n",
    "#cost = w*x # (1*3)*(3*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6-2 Tune the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "lr=0.700000\tweight\t\tvalue update\n",
      "--------------------------------------------\n",
      "Initialize:\t0.000000\n",
      "Epoch 1:\t7.000000\t7.000000\n",
      "Epoch 2:\t4.200000\t-2.800000\n",
      "Epoch 3:\t5.320000\t1.120000\n",
      "Epoch 4:\t4.872000\t-0.448000\n",
      "Epoch 5:\t5.051200\t0.179200\n",
      "Epoch 6:\t4.979520\t-0.071680\n",
      "Epoch 7:\t5.008192\t0.028672\n",
      "Epoch 8:\t4.996723\t-0.011469\n",
      "Epoch 9:\t5.001311\t0.004588\n",
      "Epoch 10:\t4.999475\t-0.001835\n",
      "Epoch 11:\t5.000210\t0.000734\n",
      "Epoch 12:\t4.999916\t-0.000294\n",
      "Epoch 13:\t5.000033\t0.000117\n",
      "Epoch 14:\t4.999987\t-0.000047\n",
      "Epoch 15:\t5.000005\t0.000019\n",
      "Epoch 16:\t4.999998\t-0.000007\n",
      "Epoch 17:\t5.000001\t0.000003\n",
      "Epoch 18:\t5.000000\t-0.000001\n",
      "Epoch 19:\t5.000000\t0.000000\n",
      "Epoch 20:\t5.000000\t0.000000\n",
      "Epoch 21:\t5.000000\t0.000000\n",
      "Epoch 22:\t5.000000\t0.000000\n",
      "Epoch 23:\t5.000000\t0.000000\n",
      "Epoch 24:\t5.000000\t0.000000\n",
      "Epoch 25:\t5.000000\t0.000000\n",
      "Epoch 26:\t5.000000\t0.000000\n",
      "Epoch 27:\t5.000000\t0.000000\n",
      "Epoch 28:\t5.000000\t0.000000\n",
      "Epoch 29:\t5.000000\t0.000000\n",
      "Epoch 30:\t5.000000\t0.000000\n",
      "Epoch 31:\t5.000000\t0.000000\n",
      "Epoch 32:\t5.000000\t0.000000\n",
      "Epoch 33:\t5.000000\t0.000000\n",
      "Epoch 34:\t5.000000\t0.000000\n",
      "Epoch 35:\t5.000000\t0.000000\n",
      "Epoch 36:\t5.000000\t0.000000\n",
      "Epoch 37:\t5.000000\t0.000000\n",
      "Epoch 38:\t5.000000\t0.000000\n",
      "Epoch 39:\t5.000000\t0.000000\n",
      "Epoch 40:\t5.000000\t0.000000\n",
      "Epoch 41:\t5.000000\t0.000000\n",
      "Epoch 42:\t5.000000\t0.000000\n",
      "Epoch 43:\t5.000000\t0.000000\n",
      "Epoch 44:\t5.000000\t0.000000\n",
      "Epoch 45:\t5.000000\t0.000000\n",
      "Epoch 46:\t5.000000\t0.000000\n",
      "Epoch 47:\t5.000000\t0.000000\n",
      "Epoch 48:\t5.000000\t0.000000\n",
      "Epoch 49:\t5.000000\t0.000000\n",
      "Epoch 50:\t5.000000\t0.000000\n",
      "Epoch 51:\t5.000000\t0.000000\n",
      "Epoch 52:\t5.000000\t0.000000\n",
      "Epoch 53:\t5.000000\t0.000000\n",
      "Epoch 54:\t5.000000\t0.000000\n",
      "Epoch 55:\t5.000000\t0.000000\n",
      "Epoch 56:\t5.000000\t0.000000\n",
      "Epoch 57:\t5.000000\t0.000000\n",
      "Epoch 58:\t5.000000\t0.000000\n",
      "Epoch 59:\t5.000000\t0.000000\n",
      "Epoch 60:\t5.000000\t0.000000\n",
      "Epoch 61:\t5.000000\t0.000000\n",
      "Epoch 62:\t5.000000\t0.000000\n",
      "Epoch 63:\t5.000000\t0.000000\n",
      "Epoch 64:\t5.000000\t0.000000\n",
      "Epoch 65:\t5.000000\t0.000000\n",
      "Epoch 66:\t5.000000\t0.000000\n",
      "Epoch 67:\t5.000000\t0.000000\n",
      "Epoch 68:\t5.000000\t0.000000\n",
      "Epoch 69:\t5.000000\t0.000000\n",
      "Epoch 70:\t5.000000\t0.000000\n",
      "Epoch 71:\t5.000000\t0.000000\n",
      "Epoch 72:\t5.000000\t0.000000\n",
      "Epoch 73:\t5.000000\t0.000000\n",
      "Epoch 74:\t5.000000\t0.000000\n",
      "Epoch 75:\t5.000000\t0.000000\n",
      "Epoch 76:\t5.000000\t0.000000\n",
      "Epoch 77:\t5.000000\t0.000000\n",
      "Epoch 78:\t5.000000\t0.000000\n",
      "Epoch 79:\t5.000000\t0.000000\n",
      "Epoch 80:\t5.000000\t0.000000\n",
      "Epoch 81:\t5.000000\t0.000000\n",
      "Epoch 82:\t5.000000\t0.000000\n",
      "Epoch 83:\t5.000000\t0.000000\n",
      "Epoch 84:\t5.000000\t0.000000\n",
      "Epoch 85:\t5.000000\t0.000000\n",
      "Epoch 86:\t5.000000\t0.000000\n",
      "Epoch 87:\t5.000000\t0.000000\n",
      "Epoch 88:\t5.000000\t0.000000\n",
      "Epoch 89:\t5.000000\t0.000000\n",
      "Epoch 90:\t5.000000\t0.000000\n",
      "Epoch 91:\t5.000000\t0.000000\n",
      "Epoch 92:\t5.000000\t0.000000\n",
      "Epoch 93:\t5.000000\t0.000000\n",
      "Epoch 94:\t5.000000\t0.000000\n",
      "Epoch 95:\t5.000000\t0.000000\n",
      "Epoch 96:\t5.000000\t0.000000\n",
      "Epoch 97:\t5.000000\t0.000000\n",
      "Epoch 98:\t5.000000\t0.000000\n",
      "Epoch 99:\t5.000000\t0.000000\n",
      "Epoch 100:\t5.000000\t0.000000\n",
      "Epoch 101:\t5.000000\t0.000000\n",
      "Epoch 102:\t5.000000\t0.000000\n",
      "Epoch 103:\t5.000000\t0.000000\n",
      "Epoch 104:\t5.000000\t0.000000\n",
      "Epoch 105:\t5.000000\t0.000000\n",
      "Epoch 106:\t5.000000\t0.000000\n",
      "Epoch 107:\t5.000000\t0.000000\n",
      "Epoch 108:\t5.000000\t0.000000\n",
      "Epoch 109:\t5.000000\t0.000000\n",
      "Epoch 110:\t5.000000\t0.000000\n",
      "Epoch 111:\t5.000000\t0.000000\n",
      "Epoch 112:\t5.000000\t0.000000\n",
      "Epoch 113:\t5.000000\t0.000000\n",
      "Epoch 114:\t5.000000\t0.000000\n",
      "Epoch 115:\t5.000000\t0.000000\n",
      "Epoch 116:\t5.000000\t0.000000\n",
      "Epoch 117:\t5.000000\t0.000000\n",
      "Epoch 118:\t5.000000\t0.000000\n",
      "Epoch 119:\t5.000000\t0.000000\n",
      "Epoch 120:\t5.000000\t0.000000\n",
      "Epoch 121:\t5.000000\t0.000000\n",
      "Epoch 122:\t5.000000\t0.000000\n",
      "Epoch 123:\t5.000000\t0.000000\n",
      "Epoch 124:\t5.000000\t0.000000\n",
      "Epoch 125:\t5.000000\t0.000000\n",
      "Epoch 126:\t5.000000\t0.000000\n",
      "Epoch 127:\t5.000000\t0.000000\n",
      "Epoch 128:\t5.000000\t0.000000\n",
      "Epoch 129:\t5.000000\t0.000000\n",
      "Epoch 130:\t5.000000\t0.000000\n",
      "Epoch 131:\t5.000000\t0.000000\n",
      "Epoch 132:\t5.000000\t0.000000\n",
      "Epoch 133:\t5.000000\t0.000000\n",
      "Epoch 134:\t5.000000\t0.000000\n",
      "Epoch 135:\t5.000000\t0.000000\n",
      "Epoch 136:\t5.000000\t0.000000\n",
      "Epoch 137:\t5.000000\t0.000000\n",
      "Epoch 138:\t5.000000\t0.000000\n",
      "Epoch 139:\t5.000000\t0.000000\n",
      "Epoch 140:\t5.000000\t0.000000\n",
      "Epoch 141:\t5.000000\t0.000000\n",
      "Epoch 142:\t5.000000\t0.000000\n",
      "Epoch 143:\t5.000000\t0.000000\n",
      "Epoch 144:\t5.000000\t0.000000\n",
      "Epoch 145:\t5.000000\t0.000000\n",
      "Epoch 146:\t5.000000\t0.000000\n",
      "Epoch 147:\t5.000000\t0.000000\n",
      "Epoch 148:\t5.000000\t0.000000\n",
      "Epoch 149:\t5.000000\t0.000000\n",
      "Epoch 150:\t5.000000\t0.000000\n",
      "Epoch 151:\t5.000000\t0.000000\n",
      "Epoch 152:\t5.000000\t0.000000\n",
      "Epoch 153:\t5.000000\t0.000000\n",
      "Epoch 154:\t5.000000\t0.000000\n",
      "Epoch 155:\t5.000000\t0.000000\n",
      "Epoch 156:\t5.000000\t0.000000\n",
      "Epoch 157:\t5.000000\t0.000000\n",
      "Epoch 158:\t5.000000\t0.000000\n",
      "Epoch 159:\t5.000000\t0.000000\n",
      "Epoch 160:\t5.000000\t0.000000\n",
      "Epoch 161:\t5.000000\t0.000000\n",
      "Epoch 162:\t5.000000\t0.000000\n",
      "Epoch 163:\t5.000000\t0.000000\n",
      "Epoch 164:\t5.000000\t0.000000\n",
      "Epoch 165:\t5.000000\t0.000000\n",
      "Epoch 166:\t5.000000\t0.000000\n",
      "Epoch 167:\t5.000000\t0.000000\n",
      "Epoch 168:\t5.000000\t0.000000\n",
      "Epoch 169:\t5.000000\t0.000000\n",
      "Epoch 170:\t5.000000\t0.000000\n",
      "Epoch 171:\t5.000000\t0.000000\n",
      "Epoch 172:\t5.000000\t0.000000\n",
      "Epoch 173:\t5.000000\t0.000000\n",
      "Epoch 174:\t5.000000\t0.000000\n",
      "Epoch 175:\t5.000000\t0.000000\n",
      "Epoch 176:\t5.000000\t0.000000\n",
      "Epoch 177:\t5.000000\t0.000000\n",
      "Epoch 178:\t5.000000\t0.000000\n",
      "Epoch 179:\t5.000000\t0.000000\n",
      "Epoch 180:\t5.000000\t0.000000\n",
      "Epoch 181:\t5.000000\t0.000000\n",
      "Epoch 182:\t5.000000\t0.000000\n",
      "Epoch 183:\t5.000000\t0.000000\n",
      "Epoch 184:\t5.000000\t0.000000\n",
      "Epoch 185:\t5.000000\t0.000000\n",
      "Epoch 186:\t5.000000\t0.000000\n",
      "Epoch 187:\t5.000000\t0.000000\n",
      "Epoch 188:\t5.000000\t0.000000\n",
      "Epoch 189:\t5.000000\t0.000000\n",
      "Epoch 190:\t5.000000\t0.000000\n",
      "Epoch 191:\t5.000000\t0.000000\n",
      "Epoch 192:\t5.000000\t0.000000\n",
      "Epoch 193:\t5.000000\t0.000000\n",
      "Epoch 194:\t5.000000\t0.000000\n",
      "Epoch 195:\t5.000000\t0.000000\n",
      "Epoch 196:\t5.000000\t0.000000\n",
      "Epoch 197:\t5.000000\t0.000000\n",
      "Epoch 198:\t5.000000\t0.000000\n",
      "Epoch 199:\t5.000000\t0.000000\n",
      "Epoch 200:\t5.000000\t0.000000\n",
      "Epoch 201:\t5.000000\t0.000000\n",
      "Epoch 202:\t5.000000\t0.000000\n",
      "Epoch 203:\t5.000000\t0.000000\n",
      "Epoch 204:\t5.000000\t0.000000\n",
      "Epoch 205:\t5.000000\t0.000000\n",
      "Epoch 206:\t5.000000\t0.000000\n",
      "Epoch 207:\t5.000000\t0.000000\n",
      "Epoch 208:\t5.000000\t0.000000\n",
      "Epoch 209:\t5.000000\t0.000000\n",
      "Epoch 210:\t5.000000\t0.000000\n",
      "Epoch 211:\t5.000000\t0.000000\n",
      "Epoch 212:\t5.000000\t0.000000\n",
      "Epoch 213:\t5.000000\t0.000000\n",
      "Epoch 214:\t5.000000\t0.000000\n",
      "Epoch 215:\t5.000000\t0.000000\n",
      "Epoch 216:\t5.000000\t0.000000\n",
      "Epoch 217:\t5.000000\t0.000000\n",
      "Epoch 218:\t5.000000\t0.000000\n",
      "Epoch 219:\t5.000000\t0.000000\n",
      "Epoch 220:\t5.000000\t0.000000\n",
      "Epoch 221:\t5.000000\t0.000000\n",
      "Epoch 222:\t5.000000\t0.000000\n",
      "Epoch 223:\t5.000000\t0.000000\n",
      "Epoch 224:\t5.000000\t0.000000\n",
      "Epoch 225:\t5.000000\t0.000000\n",
      "Epoch 226:\t5.000000\t0.000000\n",
      "Epoch 227:\t5.000000\t0.000000\n",
      "Epoch 228:\t5.000000\t0.000000\n",
      "Epoch 229:\t5.000000\t0.000000\n",
      "Epoch 230:\t5.000000\t0.000000\n",
      "Epoch 231:\t5.000000\t0.000000\n",
      "Epoch 232:\t5.000000\t0.000000\n",
      "Epoch 233:\t5.000000\t0.000000\n",
      "Epoch 234:\t5.000000\t0.000000\n",
      "Epoch 235:\t5.000000\t0.000000\n",
      "Epoch 236:\t5.000000\t0.000000\n",
      "Epoch 237:\t5.000000\t0.000000\n",
      "Epoch 238:\t5.000000\t0.000000\n",
      "Epoch 239:\t5.000000\t0.000000\n",
      "Epoch 240:\t5.000000\t0.000000\n",
      "Epoch 241:\t5.000000\t0.000000\n",
      "Epoch 242:\t5.000000\t0.000000\n",
      "Epoch 243:\t5.000000\t0.000000\n",
      "Epoch 244:\t5.000000\t0.000000\n",
      "Epoch 245:\t5.000000\t0.000000\n",
      "Epoch 246:\t5.000000\t0.000000\n",
      "Epoch 247:\t5.000000\t0.000000\n",
      "Epoch 248:\t5.000000\t0.000000\n",
      "Epoch 249:\t5.000000\t0.000000\n",
      "Epoch 250:\t5.000000\t0.000000\n",
      "Epoch 251:\t5.000000\t0.000000\n",
      "Epoch 252:\t5.000000\t0.000000\n",
      "Epoch 253:\t5.000000\t0.000000\n",
      "Epoch 254:\t5.000000\t0.000000\n",
      "Epoch 255:\t5.000000\t0.000000\n",
      "Epoch 256:\t5.000000\t0.000000\n",
      "Epoch 257:\t5.000000\t0.000000\n",
      "Epoch 258:\t5.000000\t0.000000\n",
      "Epoch 259:\t5.000000\t0.000000\n",
      "Epoch 260:\t5.000000\t0.000000\n",
      "Epoch 261:\t5.000000\t0.000000\n",
      "Epoch 262:\t5.000000\t0.000000\n",
      "Epoch 263:\t5.000000\t0.000000\n",
      "Epoch 264:\t5.000000\t0.000000\n",
      "Epoch 265:\t5.000000\t0.000000\n",
      "Epoch 266:\t5.000000\t0.000000\n",
      "Epoch 267:\t5.000000\t0.000000\n",
      "Epoch 268:\t5.000000\t0.000000\n",
      "Epoch 269:\t5.000000\t0.000000\n",
      "Epoch 270:\t5.000000\t0.000000\n",
      "Epoch 271:\t5.000000\t0.000000\n",
      "Epoch 272:\t5.000000\t0.000000\n",
      "Epoch 273:\t5.000000\t0.000000\n",
      "Epoch 274:\t5.000000\t0.000000\n",
      "Epoch 275:\t5.000000\t0.000000\n",
      "Epoch 276:\t5.000000\t0.000000\n",
      "Epoch 277:\t5.000000\t0.000000\n",
      "Epoch 278:\t5.000000\t0.000000\n",
      "Epoch 279:\t5.000000\t0.000000\n",
      "Epoch 280:\t5.000000\t0.000000\n",
      "Epoch 281:\t5.000000\t0.000000\n",
      "Epoch 282:\t5.000000\t0.000000\n",
      "Epoch 283:\t5.000000\t0.000000\n",
      "Epoch 284:\t5.000000\t0.000000\n",
      "Epoch 285:\t5.000000\t0.000000\n",
      "Epoch 286:\t5.000000\t0.000000\n",
      "Epoch 287:\t5.000000\t0.000000\n",
      "Epoch 288:\t5.000000\t0.000000\n",
      "Epoch 289:\t5.000000\t0.000000\n",
      "Epoch 290:\t5.000000\t0.000000\n",
      "Epoch 291:\t5.000000\t0.000000\n",
      "Epoch 292:\t5.000000\t0.000000\n",
      "Epoch 293:\t5.000000\t0.000000\n",
      "Epoch 294:\t5.000000\t0.000000\n",
      "Epoch 295:\t5.000000\t0.000000\n",
      "Epoch 296:\t5.000000\t0.000000\n",
      "Epoch 297:\t5.000000\t0.000000\n",
      "Epoch 298:\t5.000000\t0.000000\n",
      "Epoch 299:\t5.000000\t0.000000\n",
      "Epoch 300:\t5.000000\t0.000000\n",
      "Epoch 301:\t5.000000\t0.000000\n",
      "Epoch 302:\t5.000000\t0.000000\n",
      "Epoch 303:\t5.000000\t0.000000\n",
      "Epoch 304:\t5.000000\t0.000000\n",
      "Epoch 305:\t5.000000\t0.000000\n",
      "Epoch 306:\t5.000000\t0.000000\n",
      "Epoch 307:\t5.000000\t0.000000\n",
      "Epoch 308:\t5.000000\t0.000000\n",
      "Epoch 309:\t5.000000\t0.000000\n",
      "Epoch 310:\t5.000000\t0.000000\n",
      "Epoch 311:\t5.000000\t0.000000\n",
      "Epoch 312:\t5.000000\t0.000000\n",
      "Epoch 313:\t5.000000\t0.000000\n",
      "Epoch 314:\t5.000000\t0.000000\n",
      "Epoch 315:\t5.000000\t0.000000\n",
      "Epoch 316:\t5.000000\t0.000000\n",
      "Epoch 317:\t5.000000\t0.000000\n",
      "Epoch 318:\t5.000000\t0.000000\n",
      "Epoch 319:\t5.000000\t0.000000\n",
      "Epoch 320:\t5.000000\t0.000000\n",
      "Epoch 321:\t5.000000\t0.000000\n",
      "Epoch 322:\t5.000000\t0.000000\n",
      "Epoch 323:\t5.000000\t0.000000\n",
      "Epoch 324:\t5.000000\t0.000000\n",
      "Epoch 325:\t5.000000\t0.000000\n",
      "Epoch 326:\t5.000000\t0.000000\n",
      "Epoch 327:\t5.000000\t0.000000\n",
      "Epoch 328:\t5.000000\t0.000000\n",
      "Epoch 329:\t5.000000\t0.000000\n",
      "Epoch 330:\t5.000000\t0.000000\n",
      "Epoch 331:\t5.000000\t0.000000\n",
      "Epoch 332:\t5.000000\t0.000000\n",
      "Epoch 333:\t5.000000\t0.000000\n",
      "Epoch 334:\t5.000000\t0.000000\n",
      "Epoch 335:\t5.000000\t0.000000\n",
      "Epoch 336:\t5.000000\t0.000000\n",
      "Epoch 337:\t5.000000\t0.000000\n",
      "Epoch 338:\t5.000000\t0.000000\n",
      "Epoch 339:\t5.000000\t0.000000\n",
      "Epoch 340:\t5.000000\t0.000000\n",
      "Epoch 341:\t5.000000\t0.000000\n",
      "Epoch 342:\t5.000000\t0.000000\n",
      "Epoch 343:\t5.000000\t0.000000\n",
      "Epoch 344:\t5.000000\t0.000000\n",
      "Epoch 345:\t5.000000\t0.000000\n",
      "Epoch 346:\t5.000000\t0.000000\n",
      "Epoch 347:\t5.000000\t0.000000\n",
      "Epoch 348:\t5.000000\t0.000000\n",
      "Epoch 349:\t5.000000\t0.000000\n",
      "Epoch 350:\t5.000000\t0.000000\n",
      "Epoch 351:\t5.000000\t0.000000\n",
      "Epoch 352:\t5.000000\t0.000000\n",
      "Epoch 353:\t5.000000\t0.000000\n",
      "Epoch 354:\t5.000000\t0.000000\n",
      "Epoch 355:\t5.000000\t0.000000\n",
      "Epoch 356:\t5.000000\t0.000000\n",
      "Epoch 357:\t5.000000\t0.000000\n",
      "Epoch 358:\t5.000000\t0.000000\n",
      "Epoch 359:\t5.000000\t0.000000\n",
      "Epoch 360:\t5.000000\t0.000000\n",
      "Epoch 361:\t5.000000\t0.000000\n",
      "Epoch 362:\t5.000000\t0.000000\n",
      "Epoch 363:\t5.000000\t0.000000\n",
      "Epoch 364:\t5.000000\t0.000000\n",
      "Epoch 365:\t5.000000\t0.000000\n",
      "Epoch 366:\t5.000000\t0.000000\n",
      "Epoch 367:\t5.000000\t0.000000\n",
      "Epoch 368:\t5.000000\t0.000000\n",
      "Epoch 369:\t5.000000\t0.000000\n",
      "Epoch 370:\t5.000000\t0.000000\n",
      "Epoch 371:\t5.000000\t0.000000\n",
      "Epoch 372:\t5.000000\t0.000000\n",
      "Epoch 373:\t5.000000\t0.000000\n",
      "Epoch 374:\t5.000000\t0.000000\n",
      "Epoch 375:\t5.000000\t0.000000\n",
      "Epoch 376:\t5.000000\t0.000000\n",
      "Epoch 377:\t5.000000\t0.000000\n",
      "Epoch 378:\t5.000000\t0.000000\n",
      "Epoch 379:\t5.000000\t0.000000\n",
      "Epoch 380:\t5.000000\t0.000000\n",
      "Epoch 381:\t5.000000\t0.000000\n",
      "Epoch 382:\t5.000000\t0.000000\n",
      "Epoch 383:\t5.000000\t0.000000\n",
      "Epoch 384:\t5.000000\t0.000000\n",
      "Epoch 385:\t5.000000\t0.000000\n",
      "Epoch 386:\t5.000000\t0.000000\n",
      "Epoch 387:\t5.000000\t0.000000\n",
      "Epoch 388:\t5.000000\t0.000000\n",
      "Epoch 389:\t5.000000\t0.000000\n",
      "Epoch 390:\t5.000000\t0.000000\n",
      "Epoch 391:\t5.000000\t0.000000\n",
      "Epoch 392:\t5.000000\t0.000000\n",
      "Epoch 393:\t5.000000\t0.000000\n",
      "Epoch 394:\t5.000000\t0.000000\n",
      "Epoch 395:\t5.000000\t0.000000\n",
      "Epoch 396:\t5.000000\t0.000000\n",
      "Epoch 397:\t5.000000\t0.000000\n",
      "Epoch 398:\t5.000000\t0.000000\n",
      "Epoch 399:\t5.000000\t0.000000\n",
      "Epoch 400:\t5.000000\t0.000000\n",
      "Epoch 401:\t5.000000\t0.000000\n",
      "Epoch 402:\t5.000000\t0.000000\n",
      "Epoch 403:\t5.000000\t0.000000\n",
      "Epoch 404:\t5.000000\t0.000000\n",
      "Epoch 405:\t5.000000\t0.000000\n",
      "Epoch 406:\t5.000000\t0.000000\n",
      "Epoch 407:\t5.000000\t0.000000\n",
      "Epoch 408:\t5.000000\t0.000000\n",
      "Epoch 409:\t5.000000\t0.000000\n",
      "Epoch 410:\t5.000000\t0.000000\n",
      "Epoch 411:\t5.000000\t0.000000\n",
      "Epoch 412:\t5.000000\t0.000000\n",
      "Epoch 413:\t5.000000\t0.000000\n",
      "Epoch 414:\t5.000000\t0.000000\n",
      "Epoch 415:\t5.000000\t0.000000\n",
      "Epoch 416:\t5.000000\t0.000000\n",
      "Epoch 417:\t5.000000\t0.000000\n",
      "Epoch 418:\t5.000000\t0.000000\n",
      "Epoch 419:\t5.000000\t0.000000\n",
      "Epoch 420:\t5.000000\t0.000000\n",
      "Epoch 421:\t5.000000\t0.000000\n",
      "Epoch 422:\t5.000000\t0.000000\n",
      "Epoch 423:\t5.000000\t0.000000\n",
      "Epoch 424:\t5.000000\t0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425:\t5.000000\t0.000000\n",
      "Epoch 426:\t5.000000\t0.000000\n",
      "Epoch 427:\t5.000000\t0.000000\n",
      "Epoch 428:\t5.000000\t0.000000\n",
      "Epoch 429:\t5.000000\t0.000000\n",
      "Epoch 430:\t5.000000\t0.000000\n",
      "Epoch 431:\t5.000000\t0.000000\n",
      "Epoch 432:\t5.000000\t0.000000\n",
      "Epoch 433:\t5.000000\t0.000000\n",
      "Epoch 434:\t5.000000\t0.000000\n",
      "Epoch 435:\t5.000000\t0.000000\n",
      "Epoch 436:\t5.000000\t0.000000\n",
      "Epoch 437:\t5.000000\t0.000000\n",
      "Epoch 438:\t5.000000\t0.000000\n",
      "Epoch 439:\t5.000000\t0.000000\n",
      "Epoch 440:\t5.000000\t0.000000\n",
      "Epoch 441:\t5.000000\t0.000000\n",
      "Epoch 442:\t5.000000\t0.000000\n",
      "Epoch 443:\t5.000000\t0.000000\n",
      "Epoch 444:\t5.000000\t0.000000\n",
      "Epoch 445:\t5.000000\t0.000000\n",
      "Epoch 446:\t5.000000\t0.000000\n",
      "Epoch 447:\t5.000000\t0.000000\n",
      "Epoch 448:\t5.000000\t0.000000\n",
      "Epoch 449:\t5.000000\t0.000000\n",
      "Epoch 450:\t5.000000\t0.000000\n",
      "Epoch 451:\t5.000000\t0.000000\n",
      "Epoch 452:\t5.000000\t0.000000\n",
      "Epoch 453:\t5.000000\t0.000000\n",
      "Epoch 454:\t5.000000\t0.000000\n",
      "Epoch 455:\t5.000000\t0.000000\n",
      "Epoch 456:\t5.000000\t0.000000\n",
      "Epoch 457:\t5.000000\t0.000000\n",
      "Epoch 458:\t5.000000\t0.000000\n",
      "Epoch 459:\t5.000000\t0.000000\n",
      "Epoch 460:\t5.000000\t0.000000\n",
      "Epoch 461:\t5.000000\t0.000000\n",
      "Epoch 462:\t5.000000\t0.000000\n",
      "Epoch 463:\t5.000000\t0.000000\n",
      "Epoch 464:\t5.000000\t0.000000\n",
      "Epoch 465:\t5.000000\t0.000000\n",
      "Epoch 466:\t5.000000\t0.000000\n",
      "Epoch 467:\t5.000000\t0.000000\n",
      "Epoch 468:\t5.000000\t0.000000\n",
      "Epoch 469:\t5.000000\t0.000000\n",
      "Epoch 470:\t5.000000\t0.000000\n",
      "Epoch 471:\t5.000000\t0.000000\n",
      "Epoch 472:\t5.000000\t0.000000\n",
      "Epoch 473:\t5.000000\t0.000000\n",
      "Epoch 474:\t5.000000\t0.000000\n",
      "Epoch 475:\t5.000000\t0.000000\n",
      "Epoch 476:\t5.000000\t0.000000\n",
      "Epoch 477:\t5.000000\t0.000000\n",
      "Epoch 478:\t5.000000\t0.000000\n",
      "Epoch 479:\t5.000000\t0.000000\n",
      "Epoch 480:\t5.000000\t0.000000\n",
      "Epoch 481:\t5.000000\t0.000000\n",
      "Epoch 482:\t5.000000\t0.000000\n",
      "Epoch 483:\t5.000000\t0.000000\n",
      "Epoch 484:\t5.000000\t0.000000\n",
      "Epoch 485:\t5.000000\t0.000000\n",
      "Epoch 486:\t5.000000\t0.000000\n",
      "Epoch 487:\t5.000000\t0.000000\n",
      "Epoch 488:\t5.000000\t0.000000\n",
      "Epoch 489:\t5.000000\t0.000000\n",
      "Epoch 490:\t5.000000\t0.000000\n",
      "Epoch 491:\t5.000000\t0.000000\n",
      "Epoch 492:\t5.000000\t0.000000\n",
      "Epoch 493:\t5.000000\t0.000000\n",
      "Epoch 494:\t5.000000\t0.000000\n",
      "Epoch 495:\t5.000000\t0.000000\n",
      "Epoch 496:\t5.000000\t0.000000\n",
      "Epoch 497:\t5.000000\t0.000000\n",
      "Epoch 498:\t5.000000\t0.000000\n",
      "Epoch 499:\t5.000000\t0.000000\n",
      "Epoch 500:\t5.000000\t0.000000\n"
     ]
    }
   ],
   "source": [
    "# play for the value between: 0.9 ~ 0.01\n",
    "learning_rate = 0.7\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#first way\n",
    "'''\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))\n",
    "'''\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"lr=%f\\tweight\\t\\tvalue update\" %learning_rate)\n",
    "print(\"--------------------------------------------\")\n",
    "#second way\n",
    "with tf.Session() as session:\n",
    "    # initialize\n",
    "    session.run(init)\n",
    "    print(\"Initialize:\\t%f\" %session.run(w))\n",
    "    wf = session.run(w)\n",
    "    #session.run(train,feed_dict={x:coefficients})\n",
    "    #print(session.run(w))\n",
    "    for i in range(500):\n",
    "        # put input inside\n",
    "        session.run(train,feed_dict={x:coefficients})\n",
    "        # print the weight & 差異, think about the curve & the lowest point\n",
    "        print(\"Epoch %d:\\t%f\\t%f\" %(i+1,session.run(w),session.run(w)-wf))\n",
    "        wf = session.run(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6-3 Example  (feat. Deep Q Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Learning \n",
    "qreward = tf.reduce_sum(tf.multiply(predictedreward, action_onehot), reduction_indices = 1)\n",
    "loss = tf.reduce_mean(tf.square(networkreward - qreward))\n",
    "tf.summary.scalar('loss', loss)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.0001).minimize(loss)\n",
    "# summary\n",
    "merged_summary = tf.summary.merge_all()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Mix up Examples 1.3-1, 1.3-4, 1.6-2: Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network input\n",
    "networkstate = tf.placeholder(tf.float32, [None, 4], name=\"input\")\n",
    "networkaction = tf.placeholder(tf.int32, [None], name=\"actioninput\")\n",
    "networkreward = tf.placeholder(tf.float32,[None], name=\"groundtruth_reward\")\n",
    "action_onehot = tf.one_hot(networkaction, 2, name=\"actiononehot\")\n",
    "\n",
    "# The variable in our network: \n",
    "w1 = tf.Variable(tf.random_normal([4,16], stddev=0.35), name=\"W1\")\n",
    "w2 = tf.Variable(tf.random_normal([16,32], stddev=0.35), name=\"W2\")\n",
    "w3 = tf.Variable(tf.random_normal([32,8], stddev=0.35), name=\"W3\")\n",
    "w4 = tf.Variable(tf.random_normal([8,2], stddev=0.35), name=\"W4\")\n",
    "b1 = tf.Variable(tf.zeros([16]), name=\"B1\")\n",
    "b2 = tf.Variable(tf.zeros([32]), name=\"B2\")\n",
    "b3 = tf.Variable(tf.zeros([8]), name=\"B3\")\n",
    "b4 = tf.Variable(tf.zeros(2), name=\"B4\")\n",
    "\n",
    "# The network layout\n",
    "layer1 = tf.nn.relu(tf.add(tf.matmul(networkstate,w1), b1), name=\"Result1\")\n",
    "layer2 = tf.nn.relu(tf.add(tf.matmul(layer1,w2), b2), name=\"Result2\")\n",
    "layer3 = tf.nn.relu(tf.add(tf.matmul(layer2,w3), b3), name=\"Result3\")\n",
    "predictedreward = tf.add(tf.matmul(layer3,w4), b4, name=\"predictedReward\")\n",
    "\n",
    "# Learning \n",
    "qreward = tf.reduce_sum(tf.multiply(predictedreward, action_onehot), reduction_indices = 1)\n",
    "loss = tf.reduce_mean(tf.square(networkreward - qreward))\n",
    "tf.summary.scalar('loss', loss)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "# summary\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
