{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create placeholder\n",
    "> ## Input picture: 256\\*256*3\n",
    "> ## Output class: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pic_placehold = Tensor(\"Placeholder_2:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "class_placehold = Tensor(\"Placeholder_3:0\", shape=(?, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# functions you need\n",
    "## tf.placeholder(tf.float32, [None, pic_height, pic_width, pic_channel])\n",
    "pic_placehold =       # <- Finish your code\n",
    "# functions you need\n",
    "## tf.placeholder(XX, [XX, XX])\n",
    "class_placehold =     # <- Finish your code\n",
    "\n",
    "print(\"pic_placehold = \" + str(pic_placehold))\n",
    "print(\"class_placehold = \" + str(class_placehold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "<td>\n",
    "    pic_placehold = Tensor(\"PlaceholderXX:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    class_placehold  = Tensor(\"PlaceholderXX:0\", shape=(?, 10), dtype=int32)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the weight (Some errors will happen when you do 3. 4. , check here also if you get errors in 3. 4.) \n",
    "> ## Conv1 -- filter size: 5\\*5, channel out: 8\n",
    "> ## Conv2 -- filter size: 3\\*2, channel out: 16\n",
    "> ## NN1 -- node out: 128\n",
    "> ## NN2 -- node out: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions you need\n",
    "## w_conv_parameters = tf.Variable(tf.random_normal([filter_height, filter_width, channel_in, channel_out], stddev=0.35))\n",
    "## b_conv_parameters = tf.Variable(tf.constant(0.1, shape=[channel_out]))\n",
    "w_conv1 = tf.Variable(tf.random_normal([5, 5, 3, 8], stddev=0.35))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[8]))\n",
    "w_conv2 =     # <- Finish your code\n",
    "b_conv2 =     # <- Finish your code\n",
    "\n",
    "# functions you need\n",
    "## w_nn_parameters = tf.Variable(tf.random_normal([node_in, node_out], stddev = 0.35))\n",
    "## b_nn_parameters = tf.Variable(tf.zeros([node_out])\n",
    "w_nn1 = tf.Variable(tf.random_normal([1024, 128], stddev = 0.35))\n",
    "b_nn1 = tf.Variable(tf.zeros([128]))\n",
    "w_nn2 =       # <- Finish your code\n",
    "b_nn2 =       # <- Finish your code\n",
    "w_output = tf.Variable(tf.zeros([64,10]))\n",
    "b_output = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model: <span style=\"color:blue\">Your goal</span>\n",
    "## 3. CNN part\n",
    "> ## conv1.shape(): (?, 128, 128, 8)\n",
    "> ## max_pool1.shape(): (?, 64, 64, 8)\n",
    "> ## conv2.shape(): (?, 16, 32, 16)\n",
    "> ## max_pool2.shape(): (?, 4, 16, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN part (Make sure you have to connect each layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\tpic_height\tpic_width\tpic_channel\n",
      "conv2: (?, 16, 32, 16) \t\t->\t16\t\t32\t\t16\n",
      "activate_conv2: (?, 16, 32, 16) ->\t16\t\t32\t\t16\n",
      "max_pool2: (?, 4, 16, 16) \t->\t4\t\t16\t\t16\n"
     ]
    }
   ],
   "source": [
    "# functions you need\n",
    "## tf.nn.conv2d(tensor_in, w_conv, strides=[1, strides_height, strides_width,1], padding='SAME')\n",
    "## tf.nn.relu(tensor_in)\n",
    "## tf.nn.max_pool(tensor_in, ksize=[1,maxPooling_height,maxPooling_width,1], strides=[1,maxPooling_height,maxPooling_width,1], padding='SAME')\n",
    "conv1 = tf.nn.conv2d(pic_placehold, w_conv1, strides=[1,2,2,1], padding='SAME')\n",
    "activate_conv1 = tf.nn.relu(conv1 + b_conv1)\n",
    "max_pool1 = tf.nn.max_pool(activate_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "conv2 =              # <- Finish your code\n",
    "activate_conv2 =     # <- Finish your code\n",
    "max_pool2 =          # <- Finish your code\n",
    "\n",
    "print(\"\\t\\t\\t\\t\\tpic_height\\tpic_width\\tpic_channel\")\n",
    "print(\"conv2: %s \\t\\t->\\t%d\\t\\t%d\\t\\t%d\\nactivate_conv2: %s ->\\t%d\\t\\t%d\\t\\t%d\\nmax_pool2: %s \\t->\\t%d\\t\\t%d\\t\\t%d\" \n",
    "      %(conv2.shape, conv2.shape[1], conv2.shape[2], conv2.shape[3], \n",
    "        activate_conv2.shape, activate_conv2.shape[1], activate_conv2.shape[2], activate_conv2.shape[3], \n",
    "        max_pool2.shape, max_pool2.shape[1], max_pool2.shape[2], max_pool2.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "<td>\n",
    "    conv2: (?,16,32,16)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    activate_conv2: (?,16,32,16)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    max_pool2: (?,4,16,16)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NN part and different activate functions (Make sure you have to connect each layers)\n",
    "> ## flatten.shape(): (?, 1024)\n",
    "> ## nn1.shape(): (?, 128)\n",
    ">> ## activate_nn1: tf.nn.relu\n",
    ">> ## dropout_nn1: tf.nn.dropout\n",
    ">>> ## keep_probability: 0.5\n",
    "\n",
    "> ## nn2.shape(): (?, 64)\n",
    ">> ## activate_nn2: tf.nn.leaky_relu\n",
    ">>> ## alpha: 0.2\n",
    "\n",
    "> ## output.shape(): (?, 10)\n",
    ">> ## activate_output: tf.nn.softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NN part and different activate functions (Make sure you have to connect each layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tnode\n",
      "nn_2: (?, 64) \t\t->\t64\n",
      "activate_nn2: (?, 64)\t->\t64\n"
     ]
    }
   ],
   "source": [
    "# functions you need\n",
    "## tf.add(tf.matmul(tensor_in, w_nn), b_nn)\n",
    "## tf.nn.relu(tensor_in)\n",
    "## tf.nn.leaky_relu(tensor_in, alpha)\n",
    "flatten = tf.reshape(max_pool2, [-1, int(max_pool2.shape[1])*int(max_pool2.shape[2])*int(max_pool2.shape[3])])\n",
    "\n",
    "nn1 = tf.add(tf.matmul(flatten, w_nn1), b_nn1)\n",
    "activate_nn1 = tf.nn.relu(nn1)\n",
    "dropout_nn1 = tf.nn.dropout(activate_nn1, 0.5)\n",
    "\n",
    "nn2 =                # <- Finish your code\n",
    "activate_nn2 =       # <- Finish your code\n",
    "output = tf.nn.softmax(tf.add(tf.matmul(activate_nn2,w_output), b_output))\n",
    "\n",
    "print(\"\\t\\t\\t\\tnode\")\n",
    "print(\"nn_2: %s \\t\\t->\\t%d\\nactivate_nn2: %s\\t->\\t%d\" \n",
    "      %(nn2.shape, nn2.shape[1],\n",
    "        activate_nn2.shape, activate_nn2.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "<table> \n",
    "<tr>\n",
    "<td>\n",
    "    nn_2: (?,64)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    activate_nn2: (?,64)\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance: More topics on model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model for reinforcement learning: DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tune the model technique part is ok\n",
    "# Network placeholders\n",
    "networkstate = tf.placeholder(tf.float32, [None, 4], name=\"input\")\n",
    "networkaction = tf.placeholder(tf.int32, [None], name=\"actioninput\")\n",
    "networkreward = tf.placeholder(tf.float32,[None], name=\"groundtruth_reward\")\n",
    "action_onehot = tf.one_hot(networkaction, 2, name=\"actiononehot\")\n",
    "\n",
    "# The variables in our network\n",
    "w1 = tf.Variable(tf.random_normal([4,16], stddev=0.35), name=\"W1\")\n",
    "w2 = tf.Variable(tf.random_normal([16,32], stddev=0.35), name=\"W2\")\n",
    "w3 = tf.Variable(tf.random_normal([32,8], stddev=0.35), name=\"W3\")\n",
    "w4 = tf.Variable(tf.random_normal([8,2], stddev=0.35), name=\"W4\")\n",
    "b1 = tf.Variable(tf.zeros([16]), name=\"B1\")\n",
    "b2 = tf.Variable(tf.zeros([32]), name=\"B2\")\n",
    "b3 = tf.Variable(tf.zeros([8]), name=\"B3\")\n",
    "b4 = tf.Variable(tf.zeros(2), name=\"B4\")\n",
    "\n",
    "# The network layers\n",
    "layer1 = tf.nn.relu(tf.add(tf.matmul(networkstate,w1), b1), name=\"Result1\")\n",
    "layer2 = tf.nn.relu(tf.add(tf.matmul(layer1,w2), b2), name=\"Result2\")\n",
    "layer3 = tf.nn.relu(tf.add(tf.matmul(layer2,w3), b3), name=\"Result3\")\n",
    "predictedreward = tf.add(tf.matmul(layer3,w4), b4, name=\"predictedReward\")\n",
    "\n",
    "# Learning \n",
    "qreward = tf.reduce_sum(tf.multiply(predictedreward, action_onehot), reduction_indices = 1)\n",
    "loss = tf.reduce_mean(tf.square(networkreward - qreward))\n",
    "tf.summary.scalar('loss', loss)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model solving deep neural network issues for disappeared gradient descent: ResNet (If you want to know more details, check on the Internet or ask for our help)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
