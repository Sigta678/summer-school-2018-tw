{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorboard to visualize model structure, loss , and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model structure | loss and accuracy |\n",
    "| --- | --- |\n",
    "| ![test](https://imgur.com/ijOoUsx.png) | ![test](https://imgur.com/8PsKdMQ.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN model on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MNIST dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST is a simple computer vision dataset. \n",
    "### It consists of images of handwritten digits like these:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](https://imgur.com/9w9uz2r.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each image in MNIST has a corresponding label, a number between 0 and 9 representing the digit drawn in the image, for the pictures above the labels are: \"5 , 0 , 4 , 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's begin our task (๑•̀ㅂ•́)و✧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import tensorflow library and mnist dataset\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard : with tf.name_scope('name'): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](https://imgur.com/hlldMpv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholder (tutorial PPT page 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('Inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "    x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "with tf.name_scope('Labels'):\n",
    "    ys = tf.placeholder(tf.float32, [None, 10])\n",
    "with tf.name_scope('Placeholder_for_Dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layers (tutorial PPT page 9~23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](https://imgur.com/KZ8BnJa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, you should have the concept of model structure mentioned in page 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('model'):\n",
    "    \n",
    "    ## conv1 layer ##\n",
    "    with tf.name_scope('conv1'):\n",
    "        # page 8 + the exercises minutes ago\n",
    "        w_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1)) #filter 5x5, in channel size 1, out size 32\n",
    "        b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "        # page 13 + the exercises minutes ago\n",
    "        conv1 = tf.nn.conv2d(x_image, w_conv1, strides=[1,1,1,1], padding='SAME')\n",
    "        \n",
    "    #activation function\n",
    "    with tf.name_scope('relu'):\n",
    "        # page 20 + the exercises minutes ago\n",
    "        activate_conv1 = tf.nn.relu(conv1 + b_conv1) #output size 28x28x32\n",
    "\n",
    "    ## pool1 layer ##\n",
    "    with tf.name_scope('pool1'):\n",
    "        # page 13 + the exercises minutes ago\n",
    "        max_pool1 = tf.nn.max_pool(activate_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') #output size 14x14x32 \n",
    "\n",
    "\n",
    "    ###############You can add your own layers if you want################\n",
    "    # Make sure the channel in should be 32 which is mentioned above or you can calculate by yourself :-)\n",
    "    # Here is an example of another layers:conv2+pool2\n",
    "    '''\n",
    "    ## conv2 layer ##\n",
    "    with tf.name_scope('conv2'):\n",
    "        w_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
    "        b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "        conv2 = tf.nn.conv2d(max_pool1, w_conv2, strides=[1,1,1,1], padding='SAME')\n",
    "        \n",
    "    #activation function\n",
    "    with tf.name_scope('relu'):\n",
    "        activate_conv2 = tf.nn.relu(conv2 + b_conv2)\n",
    "\n",
    "    ## pool2 layer ##\n",
    "    with tf.name_scope('pool2'):\n",
    "        max_pool2 = tf.nn.max_pool(activate_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "     \n",
    "    '''\n",
    "    ######################################################################\n",
    "    \n",
    "    # page 22-23 + the exercises minutes ago \n",
    "\n",
    "    with tf.name_scope('flatten'):\n",
    "        '''If you've added layers above make sure that your flatten layer has attached to the last layer.\n",
    "        For the example given above, the code below should be like:\n",
    "        h_flat = tf.contrib.layers.flatten(max_pool2)'''\n",
    "        h_flat = tf.contrib.layers.flatten(max_pool1)\n",
    "\n",
    "    ## fc1 layer ##\n",
    "    with tf.name_scope('fc1'):\n",
    "        w_nn1 = tf.Variable(tf.truncated_normal([h_flat.shape[1].value, 1024], stddev = 0.1))\n",
    "        b_nn1 = tf.Variable(tf.constant(0.1, shape=[1024]))\n",
    "    \n",
    "    #activation function\n",
    "    with tf.name_scope('relu'):\n",
    "        activate_nn1 = tf.nn.relu(tf.matmul(h_flat, w_nn1) + b_nn1)\n",
    "        \n",
    "    #dropout\n",
    "    with tf.name_scope('dropout'):\n",
    "            nn1_drop = tf.nn.dropout(activate_nn1, keep_prob)\n",
    "    \n",
    "    ## fc2 layer ##\n",
    "    with tf.name_scope('fc2'):\n",
    "        w_nn2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1))\n",
    "        b_nn2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "    \n",
    "    ## output layer ##\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(tf.matmul(nn1_drop, w_nn2) + b_nn2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute loss function (tutorial PPT page 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Loss'):\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))\n",
    "    tf.summary.scalar(\"Loss\", cross_entropy) # for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization (tutorial PPT page 36) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  You can modify the learning rate: 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But make sure not to set the learning rate too low , or your VM would be very very slow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Optimization'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For example, if the number of test samples is 1000 and model classifies 952 of those correctly, then the model's accuracy is 95.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('Accuracy', acc) # for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training and recording in Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For training part, you can find more descriptions from the official website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese:  http://www.tensorfly.cn/tfdoc/tutorials/mnist_pros.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English:  https://www.tensorflow.org/versions/r1.2/get_started/mnist/beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "################################ This section may take a few minutese. Please be patient. ################################ \n",
    "\n",
    "logs_path = 'TensorBoard/' # save the tensorboard file in this folder\n",
    "merged = tf.summary.merge_all() # for tensorboard\n",
    "writer = tf.summary.FileWriter(logs_path , graph = tf.get_default_graph()) # for tensorboard\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# The following code means we train 600 times and each time we feed in 10 pictures\n",
    "for i in range(600): # We call it 600 epochs\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(10)\n",
    "    sess.run(train_step, feed_dict = {xs: batch_xs, ys: batch_ys, keep_prob:0.5} )\n",
    "    if i % 100 == 0:\n",
    "        summary = sess.run(merged, feed_dict = {xs: batch_xs, ys: batch_ys, keep_prob:0.5})\n",
    "        writer.add_summary(summary, i) # for tensorboard\n",
    "        \n",
    "writer.close() # for tensorboard      \n",
    "sess.close() # for tensorboard\n",
    "\n",
    "print(\"\\n(*´▽`*)!!!finish!!!(*´▽`*)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Open tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ tensorboard --logdir='~/summer-school-2018-tw/06-ai-deep-learning/TensorBoard/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type <span style=\"color:blue\">localhost:6006</span> at your web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](https://imgur.com/IkvXqnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You may wonder what is the difference between epoch and step in tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can look for more  descriptions in the link below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training, make sure to clean up the earlier records in the TensorBoard folder and restart the terminal.Otherwise your board will look like a mess."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
